{"cells":[{"cell_type":"markdown","metadata":{"id":"KKhSDnbnLk3D"},"source":["# Capstone: Sentiment Analysis as Classification\n","\n","In this notebook we will use the IMDB reviews dataset and your task is to predict the sentiment of reviews\n","\n","You can run this lab both locally or in Colab.\n","\n","- To run in Colab just go to `https://colab.research.google.com`, sign-in and you upload this notebook. Colab has GPU access for free.\n","- To run locally just run `jupyter notebook` and access the notebook in this lab. You would need to first install the requirements in `requirements.txt`\n","\n","Follow the instructions. Good luck!"]},{"cell_type":"code","execution_count":null,"outputs":[],"source":["!pip install textblob 'keras-nlp' 'keras-preprocessing' 'gensim' np_utils\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"fHLIKJ9KLk3F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FroiE_-QLk3G"},"outputs":[],"source":["import multiprocessing\n","import tensorflow as tf\n","import sys\n","import keras.backend as K\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, Lambda, ELU, Conv1D, MaxPooling1D, Dropout\n","import np_utils\n","from keras.preprocessing import sequence\n","from keras.preprocessing.text import Tokenizer\n","from textblob import TextBlob, Word\n","from keras_preprocessing.sequence import pad_sequences\n","from keras.initializers import Constant\n","from tensorflow import keras\n","import numpy as np\n","import random\n","import os\n","import pandas as pd\n","import gensim\n","import warnings\n","import nltk\n","import pickle\n","from tensorflow.nn import leaky_relu\n","from sklearn.model_selection import train_test_split\n","\n","TRACE = False\n","maxlen = 150\n","num_words=5\n","epochs=100\n","max_features=25000\n","batch_size = 250\n","embedding_dim=100\n","\n","\n","def set_seeds_and_trace():\n","  os.environ['PYTHONHASHSEED'] = '0'\n","  np.random.seed(42)\n","  tf.random.set_seed(42)\n","  random.seed(42)\n","  if TRACE:\n","    tf.debugging.set_log_device_placement(True)\n","\n","def set_session_with_gpus_and_cores():\n","  cores = multiprocessing.cpu_count()\n","  gpus = len(tf.config.list_physical_devices('GPU'))\n","  config = tf.compat.v1.ConfigProto( device_count = {'GPU': gpus  , 'CPU': cores} , intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","  sess = tf.compat.v1.Session(config=config)\n","  tf.compat.v1.keras.backend.set_session(sess)\n","\n","set_seeds_and_trace()\n","set_session_with_gpus_and_cores()\n","warnings.filterwarnings('ignore')\n","nltk.download('punkt')\n","textblob_tokenizer = lambda x: TextBlob(x).words"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"VTvu5AQoLk3H"},"outputs":[],"source":["(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=max_features)\n","print(len(x_train), \"Training sequences\")\n","print(len(x_val), \"Validation sequences\")\n","x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\n"]},{"cell_type":"code","source":["y_val"],"metadata":{"id":"axZ4K9reMX-l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TqTHafqfMjx_"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}